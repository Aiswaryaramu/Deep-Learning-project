ANALYSIS

The deep learning time series forecasting model was evaluated using a rolling-origin cross-validation strategy to ensure robustness under realistic temporalを見る conditions. Three evaluation folds were created, each progressively expanding the training window and forecasting future observations.

Across the three folds, the attention-based Seq2Seq LSTM model achieved RMSE values of approximately 4.99, 6.25, and 7.06 respectively. Corresponding MAE values ranged from approximately 4.18 to 6.15. The gradual increase in error across folds is expected due to the growing forecasting horizon and increased uncertainty in later segments of the time series.

The results demonstrate that the model successfully learns trend and seasonal components, particularly in earlier folds where sufficient historical context is available. Attention mechanisms enable the model to prioritize relevant past observations, improving short-to-medium horizon accuracy.

For benchmarking purposes, a classical ARIMA model was implemented using the same dataset. The ARIMA model produced an RMSE of approximately 7.19 and an MAE of approximately 6.51. Compared to the deep learning model, ARIMA exhibits weaker performance, particularly in capturing nonlinear seasonality and long-term dependencies.

The visualization further confirms that ARIMA forecasts tend to smooth the series and lag behind rapid seasonal fluctuations, whereas the deep learning model adapts more dynamically to changing patterns.

Overall, the rolling evaluation confirms that the attention-based deep learning model provides superior forecasting accuracy compared to the traditional ARIMA baseline, especially in earlier folds and high-variance regions of the time series.
